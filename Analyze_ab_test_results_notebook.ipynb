{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "You may either submit your notebook through the workspace here, or you may work from your local machine and submit through the next page.  Either way assure that your code passes the project [RUBRIC](https://review.udacity.com/#!/projects/37e27304-ad47-4eb0-a1ab-8c12f60e43d0/rubric).  **Please save regularly.**\n",
    "\n",
    "This project will assure you have mastered the subjects covered in the statistics lessons.  The hope is to have this project be as comprehensive of these topics as possible.  Good luck!\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "A/B tests are very commonly performed by data analysts and data scientists.  It is important that you get some practice working with the difficulties of these \n",
    "\n",
    "For this project, you will be working to understand the results of an A/B test run by an e-commerce website.  Your goal is to work through this notebook to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "**As you work through this notebook, follow along in the classroom and answer the corresponding quiz questions associated with each question.** The labels for each classroom concept are provided for each question.  This will assure you are on the right track as you work through the project, and you can feel more confident in your final submission meeting the criteria.  As a final check, assure you meet all the criteria on the [RUBRIC](https://review.udacity.com/#!/projects/37e27304-ad47-4eb0-a1ab-8c12f60e43d0/rubric).\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n",
    "\n",
    "To get started, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#We are setting the seed to assure you get the same answers on quizzes as we set up\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` Now, read in the `ab_data.csv` data. Store it in `df`.  **Use your dataframe to answer the questions in Quiz 1 of the classroom.**\n",
    "\n",
    "a. Read in the dataset and take a look at the top few rows here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ab_data.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Use the cell below to find the number of rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The dataframe has 294478 rows**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. The number of unique users in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**290584 unique users recorded on the site**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "d. The proportion of users converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.converted == 1].shape[0] / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.converted.mean() # Since the column consists of 0s and 1s\n",
    "                    # mean would be accurate for getting proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About 12% of users are converted**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "e. The number of times the `new_page` and `treatment` don't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"group == 'control' and landing_page == 'new_page'\").shape[0] + df.query(\"group == 'treatment' and landing_page == 'old_page'\").shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3893 times that they mismatched**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Do any of the rows have missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         0\n",
       "timestamp       0\n",
       "group           0\n",
       "landing_page    0\n",
       "converted       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No missing values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` For the rows where **treatment** does not match with **new_page** or **control** does not match with **old_page**, we cannot be sure if this row truly received the new or old page.  Use **Quiz 2** in the classroom to figure out how we should handle these rows.  \n",
    "\n",
    "a. Now use the answer to the quiz to create a new dataset that meets the specifications from the quiz.  Store your new dataframe in **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we'll get the indexes of the data we'd want to drop\n",
    "\n",
    "index1 = df.query(\"landing_page == 'old_page' and group == 'treatment'\").index\n",
    "index2 = df.query(\"landing_page == 'new_page' and group == 'control'\").index\n",
    "\n",
    "# We'd merge them into one index\n",
    "\n",
    "total_indexes = index1.append(index2)\n",
    "\n",
    "# Then all is left is to drop them and save the new dataframe in df2\n",
    "\n",
    "df2 = df.drop(total_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that means all is done as intended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use **df2** and the cells below to answer questions for **Quiz3** in the classroom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. How many unique **user_id**s are in **df2**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Same as before, which'd mean dropped data wasn't relevant to our study**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b. There is one **user_id** repeated in **df2**.  What is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773192    2\n",
       "630732    1\n",
       "811737    1\n",
       "797392    1\n",
       "795345    1\n",
       "801490    1\n",
       "799443    1\n",
       "787157    1\n",
       "793302    1\n",
       "817882    1\n",
       "842446    1\n",
       "815835    1\n",
       "805596    1\n",
       "803549    1\n",
       "809694    1\n",
       "807647    1\n",
       "895712    1\n",
       "840399    1\n",
       "836301    1\n",
       "899810    1\n",
       "834242    1\n",
       "936604    1\n",
       "934557    1\n",
       "940702    1\n",
       "938655    1\n",
       "830144    1\n",
       "828097    1\n",
       "832195    1\n",
       "838348    1\n",
       "821956    1\n",
       "         ..\n",
       "734668    1\n",
       "736717    1\n",
       "730574    1\n",
       "775632    1\n",
       "771538    1\n",
       "642451    1\n",
       "773587    1\n",
       "783828    1\n",
       "785877    1\n",
       "779734    1\n",
       "781783    1\n",
       "759256    1\n",
       "726472    1\n",
       "748999    1\n",
       "746950    1\n",
       "753093    1\n",
       "751044    1\n",
       "740803    1\n",
       "738754    1\n",
       "744897    1\n",
       "742848    1\n",
       "634271    1\n",
       "632222    1\n",
       "636316    1\n",
       "630169    1\n",
       "650647    1\n",
       "648598    1\n",
       "654741    1\n",
       "652692    1\n",
       "630836    1\n",
       "Name: user_id, Length: 290584, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this I'm gonna use .value_counts() as I know it sorts counts of values descendentally,\n",
    "# And since they're all 1's, the value with count of 2 should be at the top.\n",
    "\n",
    "df2.user_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**user_id 773192 is duplicated**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. What is the row information for the repeat **user_id**? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2.user_id == 773192]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He's from treatment group, was on the new page twice, nevertheless **Hasn't Converted**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Remove **one** of the rows with a duplicate **user_id**, but keep your dataframe as **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop([2893], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2.user_id == 773192]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Use **df2** in the cells below to answer the quiz questions related to **Quiz 4** in the classroom.\n",
    "\n",
    "a. What is the probability of an individual converting regardless of the page they receive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**12% Chance they'll convert, Regardless of what page they receive**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Given that an individual was in the `control` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2.group == \"control\"].converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**12% Chance they'd convert, given that they're in Control group**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Given that an individual was in the `treatment` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2.group == \"treatment\"].converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**11.88% Chance they'd convert, given that they're in Treatment group**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is the probability that an individual received the new page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2.landing_page == \"new_page\"].shape[0] / df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**50% Chance of any given individual getting the new page**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Consider your results from parts (a) through (d) above, and explain below whether you think there is sufficient evidence to conclude that the new treatment page leads to more conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Almost both pages has same converted rate, and in fact old page has slightly higher conversion rate, which would mean, according to the numbers above, it isn't worth to pick the new page over the old**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "Notice that because of the time stamp associated with each event, you could technically run a hypothesis test continuously as each observation was observed.  \n",
    "\n",
    "However, then the hard question is do you stop as soon as one page is considered significantly better than another or does it need to happen consistently for a certain amount of time?  How long do you run to render a decision that neither page is better than another?  \n",
    "\n",
    "These questions are the difficult parts associated with A/B tests in general.  \n",
    "\n",
    "\n",
    "`1.` For now, consider you need to make the decision just based on all the data provided.  If you want to assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%, what should your null and alternative hypotheses be?  You can state your hypothesis in terms of words or in terms of **$p_{old}$** and **$p_{new}$**, which are the converted rates for the old and new pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H_{0}: p_{new} - p_{old} \\leq 0 $$\n",
    "$$ H_{1}: p_{new} - p_{old} > 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Assume under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, assume they are equal to the **converted** rate in **ab_data.csv** regardless of the page. <br><br>\n",
    "\n",
    "Use a sample size for each page equal to the ones in **ab_data.csv**.  <br><br>\n",
    "\n",
    "Perform the sampling distribution for the difference in **converted** between the two pages over 10,000 iterations of calculating an estimate from the null.  <br><br>\n",
    "\n",
    "Use the cells below to provide the necessary parts of this simulation.  If this doesn't make complete sense right now, don't worry - you are going to work through the problems below to complete this problem.  You can use **Quiz 5** in the classroom to make sure you are on the right track.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From point `2.` $P_{new} = P_{old} = P_{conversion}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. What is the **conversion rate** for $p_{new}$ under the null? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_new = df2.converted.mean()\n",
    "\n",
    "p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. What is the **conversion rate** for $p_{old}$ under the null? <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_old = p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. What is $n_{new}$, the number of individuals in the treatment group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_new = df2[df2.group == \"treatment\"].shape[0]\n",
    "\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is $n_{old}$, the number of individuals in the control group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_old = df2[df2.group == \"control\"].shape[0]\n",
    "\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Simulate $n_{new}$ transactions with a conversion rate of $p_{new}$ under the null.  Store these $n_{new}$ 1's and 0's in **new_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11958415456610005"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this simulation it'd be better if we use binomial distribution function from numpy, since it's all 1's and 0's\n",
    "# **it's two sided like coins From Binomial Lesson **\n",
    "\n",
    "new_page_converted_sample = np.random.binomial(n_new, p_new, 10000) / n_new\n",
    "\n",
    "new_page_converted_sample.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Simulate $n_{old}$ transactions with a conversion rate of $p_{old}$ under the null.  Store these $n_{old}$ 1's and 0's in **old_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11958514118149154"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_page_converted_sample = np.random.binomial(n_old, p_old, 10000) / n_old\n",
    "\n",
    "old_page_converted_sample.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Find $p_{new}$ - $p_{old}$ for your simulated values from part (e) and (f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.8661539146438903e-07"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This value here keeps changing everytime even though the seed is the same, so I really don't know why\n",
    "# But mostly I end up getting results in favor of null hypothesis in the end\n",
    "\n",
    "obs_diff = (new_page_converted_sample - old_page_converted_sample).mean()\n",
    "\n",
    "obs_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Create 10,000 $p_{new}$ - $p_{old}$ values using the same simulation process you used in parts (a) through (g) above. Store all 10,000 values in a NumPy array called **p_diffs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_diffs = []\n",
    "\n",
    "# for _ in range(10000):\n",
    "#     old_page_converted = np.random.binomial(1, p_old, n_old)\n",
    "#     new_page_converted = np.random.binomial(1, p_new, n_new)\n",
    "#     b_conversion_diff = new_page_converted.mean() - old_page_converted.mean()\n",
    "    \n",
    "#     p_diffs.append(b_conversion_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going for a new, better way of simulating p_diffs using a numpy function that's better suiting for this purpose\n",
    "# and also more efficient, time and computing source-wise, as been kindly noted by in my last project review.\n",
    "\n",
    "p_diffs = []\n",
    "\n",
    "new_page_converted = np.random.binomial(n_new, p_new, 10000) / n_new\n",
    "old_page_converted = np.random.binomial(n_old, p_old, 10000) / n_old\n",
    "\n",
    "p_diffs.append(new_page_converted - old_page_converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Plot a histogram of the **p_diffs**.  Does this plot look like what you expected?  Use the matching problem in the classroom to assure you fully understand what was computed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0985260550>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_diffs); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diffs = np.array(p_diffs) # Somewhy, when I converted p_diffs into NumPy array before plotting it,\n",
    "                            # the plotting cell took so long to run, and never managed to complete! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally distributed histogram, just as expected from doing a statistic with large enough samples, and is also in accordance with the **Central Limit Theorem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Hypothesis Again: $$ H_{0}: p_{new} - p_{old} \\leq 0 $$\n",
    "$$ H_{1}: p_{new} - p_{old} > 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to get the p-value mentioned in the next question, we'd need our sampling distribution of the null values,\n",
    "# Then seeing whether we should stick with our null hypothesis, or reject it according to our little A/B test done.\n",
    "# We want to sample from the closest point to the alternative hypothesis, which is 0 (aka. no difference between the two models)\n",
    "\n",
    "null_vals = np.random.normal(0, p_diffs.std(), p_diffs.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the p-value we'd be comparing our simulated p_diffs array values to our actual \"average conversion difference\"\n",
    "# where we'll get the proportion of the values that are \"higher\" in this case than actual conversion difference,\n",
    "\n",
    "act_diff = df2[df2['group'] == 'treatment']['converted'].mean() - df2[df2['group'] == 'control']['converted'].mean() # Review note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09852606a0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot null distribution\n",
    "\n",
    "plt.hist(null_vals);\n",
    "\n",
    "# Seeing where our observed difference fall on null distribution\n",
    "\n",
    "plt.axvline(obs_diff, color=\"y\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAElJJREFUeJzt3X+sX/V93/Hnq3Z+bEtaTDHMta2ZZl5V80dJZhGm7A9WOjAQxVRaJDOtsVIkVxpIidZpcpo/6NIhQbuGKlpK5RarzpbUYU2iWIk36rJEVaUFMCkhGNfzDdBwYw/f1pSkisZk+t4f34+XL/b98b3X93u/N3yeD+noe77v8znnfD5cdF/3ez7nfJ2qQpLUnx+ZdAckSZNhAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6tXbSHZjPFVdcUVu2bJl0N7QcTpwYvP7UT022H1IHnnzyyb+sqvULtVvVAbBlyxaOHj066W5oOdxww+D1q1+dZC+kLiT5i1HaLXgJKMlbkzye5BtJjiX5961+dZLHkpxM8tkkb271t7T3U237lqFjfaTVTyS5eWlDkyQth1HmAF4Ffraqfga4FtiR5HrgfuCBqtoKvAzc2drfCbxcVf8QeKC1I8k2YBdwDbAD+O0ka5ZzMJKk0S0YADXwN+3tm9pSwM8Cf9jqB4Db2/rO9p62/cYkafWDVfVqVT0PTAHXLcsoJEmLNtJdQEnWJHkKOAMcAb4F/HVVnWtNpoGNbX0j8CJA2/4K8OPD9Vn2GT7XniRHkxydmZlZ/IgkSSMZKQCq6rWquhbYxOCv9p+erVl7zRzb5qpfeK59VbW9qravX7/gJLYkaYkW9RxAVf018FXgeuCyJOfvItoEnGrr08BmgLb9x4Czw/VZ9pEkrbBR7gJan+Sytv53gJ8DjgNfAf5Fa7Yb+GJbP9Te07b/jxr8s2OHgF3tLqGrga3A48s1EEnS4ozyHMAG4EC7Y+dHgIer6ktJngUOJvkPwJ8BD7X2DwH/OckUg7/8dwFU1bEkDwPPAueAu6rqteUdjiRpVAsGQFU9DbxzlvpzzHIXT1X9H+D9cxzrXuDexXdTkrTcVvWTwNJqtmXvlydy3hfuu20i59UbjwGgH2qT+iUsvRH4baCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROLRgASTYn+UqS40mOJflQq/9qku8keaottw7t85EkU0lOJLl5qL6j1aaS7B3PkCRJo1g7QptzwC9X1deTvB14MsmRtu2BqvqPw42TbAN2AdcAPwH8cZJ/1DZ/EvjnwDTwRJJDVfXscgxEkrQ4CwZAVZ0GTrf17yU5DmycZ5edwMGqehV4PskUcF3bNlVVzwEkOdjaGgCSNAGLmgNIsgV4J/BYK92d5Okk+5Osa7WNwItDu0232lx1SdIEjBwASd4GfA74cFV9F3gQeAdwLYNPCL95vuksu9c89QvPsyfJ0SRHZ2ZmRu2eJGmRRgqAJG9i8Mv/01X1eYCqeqmqXquqvwV+lx9c5pkGNg/tvgk4NU/9dapqX1Vtr6rt69evX+x4JEkjGuUuoAAPAcer6uND9Q1DzX4eeKatHwJ2JXlLkquBrcDjwBPA1iRXJ3kzg4niQ8szDEnSYo1yF9B7gF8AvpnkqVb7FeCOJNcyuIzzAvBLAFV1LMnDDCZ3zwF3VdVrAEnuBh4B1gD7q+rYMo5FkrQIo9wF9KfMfv3+8Dz73AvcO0v98Hz7SZJWjk8CS1KnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6tSCAZBkc5KvJDme5FiSD7X65UmOJDnZXte1epJ8IslUkqeTvGvoWLtb+5NJdo9vWJKkhYzyCeAc8MtV9dPA9cBdSbYBe4FHq2or8Gh7D3ALsLUte4AHYRAYwD3Au4HrgHvOh4YkaeUtGABVdbqqvt7WvwccBzYCO4EDrdkB4Pa2vhP4VA18DbgsyQbgZuBIVZ2tqpeBI8COZR2NJGlki5oDSLIFeCfwGHBVVZ2GQUgAV7ZmG4EXh3abbrW56pKkCRg5AJK8Dfgc8OGq+u58TWep1Tz1C8+zJ8nRJEdnZmZG7Z4kaZFGCoAkb2Lwy//TVfX5Vn6pXdqhvZ5p9Wlg89Dum4BT89Rfp6r2VdX2qtq+fv36xYxFkrQIo9wFFOAh4HhVfXxo0yHg/J08u4EvDtU/0O4Guh54pV0iegS4Kcm6Nvl7U6tJkiZg7Qht3gP8AvDNJE+12q8A9wEPJ7kT+Dbw/rbtMHArMAV8H/ggQFWdTfJrwBOt3ceq6uyyjEKStGgLBkBV/SmzX78HuHGW9gXcNcex9gP7F9NBSdJ4+CSwJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ1aO+kO6I1hy94vz7v94HN/BcCuBdpJWjl+ApCkThkAktQpA0CSOrVgACTZn+RMkmeGar+a5DtJnmrLrUPbPpJkKsmJJDcP1Xe02lSSvcs/FEnSYozyCeD3gR2z1B+oqmvbchggyTZgF3BN2+e3k6xJsgb4JHALsA24o7WVJE3IgncBVdWfJNky4vF2Ager6lXg+SRTwHVt21RVPQeQ5GBr++yieyxJWhaXMgdwd5Kn2yWida22EXhxqM10q81Vv0iSPUmOJjk6MzNzCd2TJM1nqQHwIPAO4FrgNPCbrZ5Z2tY89YuLVfuqantVbV+/fv0SuydJWsiSHgSrqpfOryf5XeBL7e00sHmo6SbgVFufqy5JmoAlBUCSDVV1ur39eeD8HUKHgM8k+TjwE8BW4HEGnwC2Jrka+A6DieJ/eSkdl3q10FPX4/TCfbdN7NxafgsGQJI/AG4ArkgyDdwD3JDkWgaXcV4Afgmgqo4leZjB5O454K6qeq0d527gEWANsL+qji37aCRJIxvlLqA7Zik/NE/7e4F7Z6kfBg4vqneSpLHxSWBJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdWjAAkuxPcibJM0O1y5McSXKyva5r9ST5RJKpJE8nedfQPrtb+5NJdo9nOJKkUY3yCeD3gR0X1PYCj1bVVuDR9h7gFmBrW/YAD8IgMIB7gHcD1wH3nA8NSdJkLBgAVfUnwNkLyjuBA239AHD7UP1TNfA14LIkG4CbgSNVdbaqXgaOcHGoSJJW0FLnAK6qqtMA7fXKVt8IvDjUbrrV5qpLkiZkuSeBM0ut5qlffIBkT5KjSY7OzMwsa+ckST+w1AB4qV3aob2eafVpYPNQu03AqXnqF6mqfVW1vaq2r1+/fondkyQtZKkBcAg4fyfPbuCLQ/UPtLuBrgdeaZeIHgFuSrKuTf7e1GqSpAlZu1CDJH8A3ABckWSawd089wEPJ7kT+Dbw/tb8MHArMAV8H/ggQFWdTfJrwBOt3ceq6sKJZUnSClowAKrqjjk23ThL2wLumuM4+4H9i+qdJGlsfBJYkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASerUJQVAkheSfDPJU0mOttrlSY4kOdle17V6knwiyVSSp5O8azkGIElamuX4BPDPquraqtre3u8FHq2qrcCj7T3ALcDWtuwBHlyGc0uSlmgcl4B2Agfa+gHg9qH6p2rga8BlSTaM4fySpBFcagAU8EdJnkyyp9WuqqrTAO31ylbfCLw4tO90q71Okj1JjiY5OjMzc4ndkyTNZe0l7v+eqjqV5ErgSJI/n6dtZqnVRYWqfcA+gO3bt1+0XZK0PC4pAKrqVHs9k+QLwHXAS0k2VNXpdonnTGs+DWwe2n0TcOpSzq+Lbdn75Ul3QdIPiSVfAkry95K8/fw6cBPwDHAI2N2a7Qa+2NYPAR9odwNdD7xy/lKRJGnlXcongKuALyQ5f5zPVNV/T/IE8HCSO4FvA+9v7Q8DtwJTwPeBD17CuSVJl2jJAVBVzwE/M0v9r4AbZ6kXcNdSzydp8iZ1ifGF+26byHnf6HwSWJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1Km1k+7AG9GWvV+edBckaUEGgKRVb5J/VL1w320TO/e4rfgloCQ7kpxIMpVk70qfX5I0sKIBkGQN8EngFmAbcEeSbSvZB0nSwEp/ArgOmKqq56rq/wIHgZ0r3AdJEis/B7AReHHo/TTw7nGdzMlYSZdqUr9HVmLuYaUDILPU6nUNkj3Anvb2b5KcGHuvluYK4C8n3YkJWtT4/8n5lfvfO5bOTIA//37HvyJjz/2XtPs/GKXRSgfANLB56P0m4NRwg6raB+xbyU4tRZKjVbV90v2YFMfv+Hsd/xtp7Cs9B/AEsDXJ1UneDOwCDq1wHyRJrPAngKo6l+Ru4BFgDbC/qo6tZB8kSQMr/iBYVR0GDq/0ecdg1V+mGjPH37eex/+GGXuqauFWkqQ3HL8MTpI6ZQBcIMnlSY4kOdle183RbndrczLJ7qH6P07yzfZVF59Ikgv2+7dJKskV4x7LUoxr/El+I8mfJ3k6yReSXLZSY1rIQl9PkuQtST7btj+WZMvQto+0+okkN496zNVkucefZHOSryQ5nuRYkg+t3GgWbxw//7ZtTZI/S/Kl8Y9iiarKZWgBfh3Y29b3AvfP0uZy4Ln2uq6tr2vbHmdw23uA/wbcMrTfZgYT4H8BXDHpsa7k+IGbgLVt/f7Zjjuh8a4BvgX8JPBm4BvAtgva/Gvgd9r6LuCzbX1ba/8W4Op2nDWjHHO1LGMa/wbgXa3N24H/1dP4h/b7N8BngC9NepxzLX4CuNhO4EBbPwDcPkubm4EjVXW2ql4GjgA7kmwAfrSq/mcN/g/41AX7PwD8Oy54+G2VGcv4q+qPqupc2/9rDJ4BWQ1G+XqS4f8mfwjc2D7Z7AQOVtWrVfU8MNWO98P0lSfLPv6qOl1VXweoqu8Bxxl8C8BqNI6fP0k2AbcBv7cCY1gyA+BiV1XVaYD2euUsbWb7SouNbZmepU6S9wHfqapvjKPTy2gs47/ALzL4dLAazDWWWdu0EHsF+PF59h3lmKvFOMb//7XLJe8EHlvGPi+ncY3/txj8sfe3y9/l5dPlvweQ5I+Bvz/Lpo+OeohZajVXPcnfbce+acTjj9VKj/+Cc38UOAd8esRzjduCfZ6nzVz12f6wWq2f+sYx/sFOyduAzwEfrqrvLrmH47Xs40/yXuBMVT2Z5IZL7N9YdRkAVfVzc21L8lKSDVV1ul3SODNLs2nghqH3m4CvtvqmC+qngHcwuEb4jTYnugn4epLrqup/X8JQlmQC4z9/7N3Ae4Eb2yWi1WDBrycZajOdZC3wY8DZBfZd6JirxVjGn+RNDH75f7qqPj+eri+LcYz/fcD7ktwKvBX40ST/par+1XiGcAkmPQmx2hbgN3j9JOivz9LmcuB5BhOg69r65W3bE8D1/GAS9NZZ9n+B1TsJPJbxAzuAZ4H1kx7jBWNZy2AS+2p+MAl4zQVt7uL1k4APt/VreP0k4HMMJhUXPOZqWcY0/jCY//mtSY9vEuO/YN8bWMWTwBPvwGpbGFzbexQ42V7P/2LbDvzeULtfZDDpMwV8cKi+HXiGwR0B/4n2sN0F51jNATCW8bd2LwJPteV3Jj3WoT7fyuBOlW8BH221jwHva+tvBf5rG8PjwE8O7fvRtt8JXn/H10XHXK3Lco8f+KcMLpE8PfTzvugPodWyjOPnP7R9VQeATwJLUqe8C0iSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUqf8HyRia8KIPQfgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f098474d470>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot null distribution\n",
    "\n",
    "plt.hist(null_vals);\n",
    "\n",
    "# Seeing where our observed difference fall on null distribution\n",
    "\n",
    "plt.axvline(act_diff, color=\"r\"); # Here I've changed axvline to act_diff, because it makes sense to use this value,\n",
    "                                  # since we're also getting p-value using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now to get **P-Value** we'd want to get extreme values to the right, since our alt.Hypothesis states that diff between new page and old page, in terms of conversion, is greater than 0.\n",
    "\n",
    "**Meaning the extreme values that are Greater than our observed statistic, which are in favor of the alternative hypothesis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j. What proportion of the **p_diffs** are greater than the actual difference observed in **ab_data.csv**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90510000000000002"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p_diffs > act_diff).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k. Please explain using the vocabulary you've learned in this course what you just computed in part **j.**  What is this value called in scientific studies?  What does this value mean in terms of whether or not there is a difference between the new and old pages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With such a high **P-Value** it's most likely that our statistic came from our null distribution.\n",
    "\n",
    "It means the likelihood of obtaining our observed statistic or one more \"extreme\" value -that comes from the altrenative hypothesis-, given that our null hypothesis is true.\n",
    "\n",
    "which in simpler terms -I hope- is, **the probability of getting one or more extreme difference between new_page and old_page that's under the alternative hypothesis**, if there's no difference or even old_page is still better, that is our null hypothesis is true.\n",
    "Then getting that/those extreme value(s) would be something close to coincidence or luck. \n",
    "But if this P-Value were to be low -lower than our alpha level, threshold for type 1 errors- we would be calling the probability of getting those values not by sheer luck, meaning it wasn't a coincidence that we got difference in favor of the new_page, but rather due to fallibility of our null hypothesis, then we'd reject it, and Alternative hypothesis would be true.\n",
    "\n",
    "**But in this case, since our P-Value is too much higher than our threshold for type1 errors, then we'd fail to reject the Null-Hypothesis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l. We could also use a built-in to achieve similar results.  Though using the built-in might be easier to code, the above portions are a walkthrough of the ideas that are critical to correctly thinking about statistical significance. Fill in the below to calculate the number of conversions for each page, as well as the number of individuals who received each page. Let `n_old` and `n_new` refer the the number of rows associated with the old page and new pages, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "convert_old = df2.query(\"converted == 1 and group == 'control'\").shape[0]\n",
    "convert_new = df2.query(\"converted == 1 and group == 'treatment'\").shape[0]\n",
    "n_old = df2.query(\"landing_page == 'old_page'\").shape[0]\n",
    "n_new = df2.query(\"landing_page == 'new_page'\").shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m. Now use `stats.proportions_ztest` to compute your test statistic and p-value.  [Here](https://docs.w3cub.com/statsmodels/generated/statsmodels.stats.proportion.proportions_ztest/) is a helpful link on using the built in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3109241984234394, 0.90505831275902449)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll set our parameters as follows: count -- array of successes of the two group which in this case is conversions\n",
    "# nobs : number of observations, which refers to the number of users in the two groups\n",
    "# Value : is set to 0 since we need to test p_value under the hypothesis that difference is 0\n",
    "# alternative : is set to smaller in this case because we want to test that old_page mean is smaller than new_page mean\n",
    "# prop_var : False since we need to calculate our values based on our proportions, not mere 0's and 1's\n",
    "\n",
    "z_score, p_value = sm.stats.proportions_ztest(count=[convert_old, convert_new], \n",
    "                                              nobs=[n_old, n_new],\n",
    "                                              value=0,\n",
    "                                              alternative='smaller',\n",
    "                                              prop_var=False)\n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n. What do the z-score and p-value you computed in the previous question mean for the conversion rates of the old and new pages?  Do they agree with the findings in parts **j.** and **k.**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**z-score is a value that describes the relationship between a data point and the mean, and is measured in terms of the standard deviation for a specific data point from the mean and with a z-score of 1.3 it's most likely isn't big enough for us to prefer new page over the old one**\n",
    "\n",
    "**And for the p-value of 90% it's consistent with what we got earlier in our statistic, though not the same, that our data most likely has come from the null, and it's enough of an evidence that we shouldn't reject the null, and thus stick with the old page.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "`1.` In this final part, you will see that the result you achieved in the A/B test in Part II above can also be achieved by performing regression.<br><br> \n",
    "\n",
    "a. Since each row is either a conversion or no conversion, what type of regression should you be performing in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The goal is to use **statsmodels** to fit the regression model you specified in part **a.** to see if there is a significant difference in conversion based on which page a customer receives. However, you first need to create in df2 a column for the intercept, and create a dummy variable column for which page each user received.  Add an **intercept** column, as well as an **ab_page** column, which is 1 when an individual receives the **treatment** and 0 if **control**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"ab_page\"] = pd.get_dummies(df2['group'])['treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   ab_page  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        1  \n",
       "4        0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head() # For Accuracy checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping landing_page col. to de-clutter our df\n",
    "\n",
    "df2 = df2.drop('landing_page', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>converted</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group  converted  ab_page\n",
       "0   851104  2017-01-21 22:11:48.556739    control          0        0\n",
       "1   804228  2017-01-12 08:01:45.159739    control          0        0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment          0        1\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment          0        1\n",
       "4   864975  2017-01-21 01:52:26.210827    control          1        0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Use **statsmodels** to instantiate your regression model on the two columns you created in part b., then fit the model using the two columns you created in part **b.** to predict whether or not an individual converts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "df2['intercept'] = 1\n",
    "\n",
    "log_model = sm.Logit(df2['converted'], df2[['intercept', 'ab_page']])\n",
    "\n",
    "results = log_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Provide the summary of your model below, and use it as necessary to answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>       <td>No. Iterations:</td>    <td>6.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>    <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-05-23 20:39</td>       <td>AIC:</td>        <td>212780.3502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>            <td>BIC:</td>        <td>212801.5095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>         <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290582</td>          <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9888</td>  <td>0.0081</td>  <td>-246.6690</td> <td>0.0000</td> <td>-2.0046</td> <td>-1.9730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0150</td>  <td>0.0114</td>   <td>-1.3109</td>  <td>0.1899</td> <td>-0.0374</td> <td>0.0074</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            No. Iterations:   6.0000     \n",
       "Dependent Variable: converted        Pseudo R-squared: 0.000      \n",
       "Date:               2021-05-23 20:39 AIC:              212780.3502\n",
       "No. Observations:   290584           BIC:              212801.5095\n",
       "Df Model:           1                Log-Likelihood:   -1.0639e+05\n",
       "Df Residuals:       290582           LL-Null:          -1.0639e+05\n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9888    0.0081  -246.6690  0.0000  -2.0046  -1.9730\n",
       "ab_page      -0.0150    0.0114    -1.3109  0.1899  -0.0374   0.0074\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. What is the p-value associated with **ab_page**? Why does it differ from the value you found in **Part II**?<br><br>  **Hint**: What are the null and alternative hypotheses associated with your regression model, and how do they compare to the null and alternative hypotheses in **Part II**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our **Old Hypothesis** from part2 Again: $$ H_{0}: p_{new} - p_{old} \\leq 0 $$\n",
    "$$ H_{1}: p_{new} - p_{old} > 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our **New Hypothesis** for Regression stats, and as they come by default: \n",
    "$$H_{0}: \\beta_{0} = 0$$\n",
    "$$H_{1}: \\beta_{0} \\neq0$$\n",
    "\n",
    "As we want to see if our new page has any implication on conversion, even if it's negative, hence other than 0.\n",
    "\n",
    "So, this hypothesis tests againt the efficency of using one variable to predicet the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Here, regarding `ab_page`, we got a P-Value of 0.1899 or %19 is much higher than our alpha level of 0.05, and states that **the relationship between new_page and conversion rate isn't Stastically Significant Enough for us to adopt the new page.** Which aligns with what we got earlier that our null hypothesis stays true and we fail to reject it.\n",
    "\n",
    "As to why it differed from previous P-Value, is because it measures something else, and it's whether there's enough evidence to say that the new page had an impact on conversion rates or not, in other words, statistically if the slope predicting conversion value to be of 1 or 0 is not equal to 0 and there's a possibility to predict using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Now, you are considering other things that might influence whether or not an individual converts.  Discuss why it is a good idea to consider other factors to add into your regression model.  Are there any disadvantages to adding additional terms into your regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd want to look at why an individual might convert from multiple angles to determine or see what could fit well to describe the causal behind conversion, so considering other in our regression model can be a good idea, But that'd let be other issues for us to deal us, such as co-linearity or multicollinearity between our multiple x values, such that x values can end up corelating between each other more than with the y value, Also when adding multi-linear variables we can have Higher Order Terms such as: quadratics, cubics or interaction. And this would happen if we wanted to add more than one X variable into our model, then theses X variables wouldn't have a parallel lines, so then we'd create another merged variable -namely a column- that multiplies the two variables, and then we'd get it into our regression model to see the relationship between the new variable and the Y variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Now along with testing if the conversion rate changes for different pages, also add an effect based on which country a user lives in. You will need to read in the **countries.csv** dataset and merge together your datasets on the appropriate rows.  [Here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.join.html) are the docs for joining tables. \n",
    "\n",
    "Does it appear that country had an impact on conversion?  Don't forget to create dummy variables for these country columns - **Hint: You will need two columns for the three dummy variables.** Provide the statistical output as well as a written response to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since they both share user_id column we'd either add it as an index\n",
    "# or remove it from either of them, but we'll stick with the first option\n",
    "\n",
    "countries_df = pd.read_csv('./countries.csv')\n",
    "\n",
    "\n",
    "countries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>converted</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>intercept</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>851104</th>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804228</th>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661590</th>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853541</th>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864975</th>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp      group  converted  ab_page  intercept  \\\n",
       "user_id                                                                         \n",
       "851104   2017-01-21 22:11:48.556739    control          0        0          1   \n",
       "804228   2017-01-12 08:01:45.159739    control          0        0          1   \n",
       "661590   2017-01-11 16:55:06.154213  treatment          0        1          1   \n",
       "853541   2017-01-08 18:28:03.143765  treatment          0        1          1   \n",
       "864975   2017-01-21 01:52:26.210827    control          1        0          1   \n",
       "\n",
       "        country  \n",
       "user_id          \n",
       "851104       US  \n",
       "804228       US  \n",
       "661590       US  \n",
       "853541       US  \n",
       "864975       US  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since they both share user_id column we'd either add it as an index\n",
    "# or remove it from either of them, but we'll stick with the first option\n",
    "\n",
    "new_df = df2.set_index('user_id').join(countries_df.set_index('user_id'), how='inner')\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'CA', 'UK'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.country.unique() # We've got 3 countries in country column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    203619\n",
       "UK     72466\n",
       "CA     14499\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.country.value_counts() # US has the most anticipation records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>851104</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804228</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661590</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853541</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864975</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936923</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679687</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719014</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817355</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839785</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929503</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834487</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803683</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944475</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718956</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644214</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847721</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888545</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650559</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935734</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740805</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759875</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905617</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746742</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892356</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773302</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913579</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736159</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690284</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883344</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825594</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875688</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927527</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937338</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679096</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691699</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807595</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924816</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846225</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740310</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677163</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832080</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834362</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925675</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923948</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857744</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643562</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755438</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908354</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718310</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822004</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945152</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734608</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697314</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715931</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290584 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CA  UK  US\n",
       "user_id            \n",
       "851104    0   0   1\n",
       "804228    0   0   1\n",
       "661590    0   0   1\n",
       "853541    0   0   1\n",
       "864975    0   0   1\n",
       "936923    0   0   1\n",
       "679687    1   0   0\n",
       "719014    0   0   1\n",
       "817355    0   1   0\n",
       "839785    1   0   0\n",
       "929503    0   1   0\n",
       "834487    0   0   1\n",
       "803683    0   0   1\n",
       "944475    0   0   1\n",
       "718956    0   0   1\n",
       "644214    0   0   1\n",
       "847721    0   0   1\n",
       "888545    0   0   1\n",
       "650559    1   0   0\n",
       "935734    0   0   1\n",
       "740805    0   0   1\n",
       "759875    0   1   0\n",
       "793849    0   0   1\n",
       "905617    0   1   0\n",
       "746742    0   0   1\n",
       "892356    0   1   0\n",
       "773302    0   0   1\n",
       "913579    0   0   1\n",
       "736159    0   0   1\n",
       "690284    0   0   1\n",
       "...      ..  ..  ..\n",
       "776137    0   0   1\n",
       "883344    1   0   0\n",
       "825594    0   1   0\n",
       "875688    0   0   1\n",
       "927527    0   0   1\n",
       "789177    0   0   1\n",
       "937338    0   1   0\n",
       "733101    0   0   1\n",
       "679096    0   0   1\n",
       "691699    0   0   1\n",
       "807595    0   0   1\n",
       "924816    0   0   1\n",
       "846225    0   0   1\n",
       "740310    0   0   1\n",
       "677163    0   0   1\n",
       "832080    0   0   1\n",
       "834362    0   0   1\n",
       "925675    0   0   1\n",
       "923948    0   0   1\n",
       "857744    0   0   1\n",
       "643562    1   0   0\n",
       "755438    0   0   1\n",
       "908354    0   0   1\n",
       "718310    0   0   1\n",
       "822004    1   0   0\n",
       "751197    0   0   1\n",
       "945152    0   0   1\n",
       "734608    0   0   1\n",
       "697314    0   0   1\n",
       "715931    0   1   0\n",
       "\n",
       "[290584 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for columns' order in dummy series\n",
    "\n",
    "pd.get_dummies(new_df['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>converted</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>intercept</th>\n",
       "      <th>country</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>851104</th>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804228</th>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661590</th>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853541</th>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864975</th>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp      group  converted  ab_page  intercept  \\\n",
       "user_id                                                                         \n",
       "851104   2017-01-21 22:11:48.556739    control          0        0          1   \n",
       "804228   2017-01-12 08:01:45.159739    control          0        0          1   \n",
       "661590   2017-01-11 16:55:06.154213  treatment          0        1          1   \n",
       "853541   2017-01-08 18:28:03.143765  treatment          0        1          1   \n",
       "864975   2017-01-21 01:52:26.210827    control          1        0          1   \n",
       "\n",
       "        country  CA  UK  US  \n",
       "user_id                      \n",
       "851104       US   0   0   1  \n",
       "804228       US   0   0   1  \n",
       "661590       US   0   0   1  \n",
       "853541       US   0   0   1  \n",
       "864975       US   0   0   1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[[\"CA\", \"UK\", \"US\"]] = pd.get_dummies(new_df['country'])\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're dropping country col. since now it would only clutter our df\n",
    "\n",
    "new_df = new_df.drop('country', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>       <td>No. Iterations:</td>    <td>6.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>    <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-05-23 20:39</td>       <td>AIC:</td>        <td>212781.1253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>            <td>BIC:</td>        <td>212823.4439</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>3</td>         <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290580</td>          <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9893</td>  <td>0.0089</td>  <td>-223.7628</td> <td>0.0000</td> <td>-2.0067</td> <td>-1.9718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0149</td>  <td>0.0114</td>   <td>-1.3069</td>  <td>0.1912</td> <td>-0.0374</td> <td>0.0075</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>-0.0408</td>  <td>0.0269</td>   <td>-1.5161</td>  <td>0.1295</td> <td>-0.0934</td> <td>0.0119</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>0.0099</td>   <td>0.0133</td>   <td>0.7433</td>   <td>0.4573</td> <td>-0.0162</td> <td>0.0359</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            No. Iterations:   6.0000     \n",
       "Dependent Variable: converted        Pseudo R-squared: 0.000      \n",
       "Date:               2021-05-23 20:39 AIC:              212781.1253\n",
       "No. Observations:   290584           BIC:              212823.4439\n",
       "Df Model:           3                Log-Likelihood:   -1.0639e+05\n",
       "Df Residuals:       290580           LL-Null:          -1.0639e+05\n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9893    0.0089  -223.7628  0.0000  -2.0067  -1.9718\n",
       "ab_page      -0.0149    0.0114    -1.3069  0.1912  -0.0374   0.0075\n",
       "CA           -0.0408    0.0269    -1.5161  0.1295  -0.0934   0.0119\n",
       "UK            0.0099    0.0133     0.7433  0.4573  -0.0162   0.0359\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our new logistic model will contain X-vars as intercept, CA,UK\n",
    "# We'll then make US as our comparing-to baseline, since it has the most records among the 3 \n",
    "\n",
    "log_mod2 = sm.Logit(new_df['converted'], new_df[['intercept', 'ab_page', 'CA', 'UK']])\n",
    "results2 = log_mod2.fit()\n",
    "\n",
    "results2.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the 2 countries has P-Values that's higher than the default threshold for type1 errors of 0.05, and thus they're NOT Stastically significant in predicting our dependent, Y variable, and we can take it as an evidence that country, according to our statistic, Doesn't impact conversion rates.\n",
    "\n",
    "Same conclusion also applies on new page thus far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The Reciprocate for CA: 1.0416437559600236',\n",
       " 'And the exp for UK: 1.0099491671175422')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since CA has Coeffeceny that's under 0, we'll get Reciprocate value for it,\n",
    "# so that it's easier when communicating it's results,\n",
    "# (Aka. instead of saying increase of conversion rate for every unit, we'd say decrease)\n",
    "\n",
    "f\"The Reciprocate for CA: {1 / np.exp(-0.0408)}\" , f\"And the exp for UK: {np.exp(0.0099)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the US:\n",
    "- CA is 1.041 **Less Inclined** to convert\n",
    "- UK is 1.009 **More Inclined** to convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Though you have now looked at the individual factors of country and page on conversion, we would now like to look at an interaction between page and country to see if there significant effects on conversion.  Create the necessary additional columns, and fit the new model.  \n",
    "\n",
    "Provide the summary results, and your conclusions based on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>converted</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>intercept</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "      <th>US_new_page</th>\n",
       "      <th>UK_new_page</th>\n",
       "      <th>CA_new_page</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>851104</th>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804228</th>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661590</th>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853541</th>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864975</th>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp      group  converted  ab_page  intercept  \\\n",
       "user_id                                                                         \n",
       "851104   2017-01-21 22:11:48.556739    control          0        0          1   \n",
       "804228   2017-01-12 08:01:45.159739    control          0        0          1   \n",
       "661590   2017-01-11 16:55:06.154213  treatment          0        1          1   \n",
       "853541   2017-01-08 18:28:03.143765  treatment          0        1          1   \n",
       "864975   2017-01-21 01:52:26.210827    control          1        0          1   \n",
       "\n",
       "         CA  UK  US  US_new_page  UK_new_page  CA_new_page  \n",
       "user_id                                                     \n",
       "851104    0   0   1            0            0            0  \n",
       "804228    0   0   1            0            0            0  \n",
       "661590    0   0   1            1            0            0  \n",
       "853541    0   0   1            1            0            0  \n",
       "864975    0   0   1            0            0            0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to investigate the interaction we'll have to make a column for new_page + country\n",
    "# Using series* series from pandas to ensure that new column have positive \"1\", when both of series have 1\n",
    "\n",
    "new_df['US_new_page'] = new_df['US'] * new_df['ab_page']\n",
    "new_df['UK_new_page'] = new_df['UK'] * new_df['ab_page']\n",
    "new_df['CA_new_page'] = new_df['CA'] * new_df['ab_page']\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>       <td>No. Iterations:</td>    <td>6.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>    <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-05-23 20:39</td>       <td>AIC:</td>        <td>212782.6602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>            <td>BIC:</td>        <td>212846.1381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>5</td>         <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290578</td>          <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>        <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>   <td>-1.9865</td>  <td>0.0096</td>  <td>-206.3440</td> <td>0.0000</td> <td>-2.0053</td> <td>-1.9676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>     <td>-0.0206</td>  <td>0.0137</td>   <td>-1.5052</td>  <td>0.1323</td> <td>-0.0473</td> <td>0.0062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>          <td>-0.0057</td>  <td>0.0188</td>   <td>-0.3057</td>  <td>0.7598</td> <td>-0.0426</td> <td>0.0311</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>          <td>-0.0175</td>  <td>0.0377</td>   <td>-0.4652</td>  <td>0.6418</td> <td>-0.0914</td> <td>0.0563</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK_new_page</th> <td>0.0314</td>   <td>0.0266</td>   <td>1.1807</td>   <td>0.2377</td> <td>-0.0207</td> <td>0.0835</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA_new_page</th> <td>-0.0469</td>  <td>0.0538</td>   <td>-0.8718</td>  <td>0.3833</td> <td>-0.1523</td> <td>0.0585</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            No. Iterations:   6.0000     \n",
       "Dependent Variable: converted        Pseudo R-squared: 0.000      \n",
       "Date:               2021-05-23 20:39 AIC:              212782.6602\n",
       "No. Observations:   290584           BIC:              212846.1381\n",
       "Df Model:           5                Log-Likelihood:   -1.0639e+05\n",
       "Df Residuals:       290578           LL-Null:          -1.0639e+05\n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9865    0.0096  -206.3440  0.0000  -2.0053  -1.9676\n",
       "ab_page      -0.0206    0.0137    -1.5052  0.1323  -0.0473   0.0062\n",
       "UK           -0.0057    0.0188    -0.3057  0.7598  -0.0426   0.0311\n",
       "CA           -0.0175    0.0377    -0.4652  0.6418  -0.0914   0.0563\n",
       "UK_new_page   0.0314    0.0266     1.1807  0.2377  -0.0207   0.0835\n",
       "CA_new_page  -0.0469    0.0538    -0.8718  0.3833  -0.1523   0.0585\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again we'll use US as baseline\n",
    "\n",
    "log_mod3 = sm.Logit(new_df['converted'], new_df[['intercept', 'ab_page', 'UK','CA', 'UK_new_page', 'CA_new_page']])\n",
    "results3 = log_mod3.fit()\n",
    "\n",
    "results3.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The Reciprocate for new_page_CA: 1.048017202119183',\n",
       " 'And the exp for new_page_UK: 1.0318981806179213')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"The Reciprocate for new_page_CA: {1 / np.exp(-0.0469)}\" , f\"And the exp for new_page_UK: {np.exp(0.0314)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to treatment group from US:\n",
    "\n",
    "- Treatment group from CA is 1.048 **Less Inclined** to convert.\n",
    "- Treatment group from UK is 1.032 **More Inclined** to convert.\n",
    "\n",
    "Now, summing up, compared to US, the likeability to convert differs, but nonetheless too slight to take it as an evident that country really plays a role in individuals deciding to convert or not, or for us to take as a significant evident in our statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "According to our above analysis, when we tested conversion rates against the new page, we found that it had little to negative impact on clients' conversions.\n",
    "And then we tested it, including one more variable to our analysis using regression model, and found that the results weren't **Stastically Significant Enough** for us to affirm that this new variable (Aka. Country) had a significant, or admittable impact on conversion rates.\n",
    "Then, After fetching the relationship between conversion rates and people from different countries, given that they're from the new page, to find whether it actually mattered in our analysis or conclusions and the result was this: \n",
    ">Compared to treatment group from US:\n",
    "- Treatment group from CA is 1.048 **Less Inclined** to convert.\n",
    "- Treatment group from UK is 1.032 **More Inclined** to convert.\n",
    "so with indication level of effect under 1.05 it denies any strong correlation between (country, new page) and conversion rate.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "**It would be better for now to stick to the old page, until we find another substitute to test, or maybe another feature that could impact our webpage users' conversion rates, hopefully in positive manner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Analyze_ab_test_results_notebook.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
